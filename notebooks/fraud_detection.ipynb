{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "708f3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve, auc, f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c8ba2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_country = pd.read_csv('../data/IpAddress_to_Country.csv')\n",
    "creditcard = pd.read_csv('../data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd02e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Data Analysis and Preprocessing\n",
    "\n",
    "# Handle Missing Values\n",
    "fraud_data = fraud_data.dropna()  # Drop rows with missing values\n",
    "creditcard = creditcard.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc5a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "fraud_data = fraud_data.drop_duplicates()\n",
    "creditcard = creditcard.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91750fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct Data Types\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time'])\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time'])\n",
    "fraud_data['ip_address'] = fraud_data['ip_address'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1926ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Datasets for Geolocation Analysis\n",
    "def map_ip_to_country(ip, ip_country_df):\n",
    "    for _, row in ip_country_df.iterrows():\n",
    "        if row['lower_bound_ip_address'] <= ip <= row['upper_bound_ip_address']:\n",
    "            return row['country']\n",
    "    return 'Unknown'\n",
    "\n",
    "fraud_data['country'] = fraud_data['ip_address'].apply(lambda x: map_ip_to_country(x, ip_country))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5bb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering for Fraud_Data\n",
    "fraud_data['hour_of_day'] = fraud_data['purchase_time'].dt.hour\n",
    "fraud_data['day_of_week'] = fraud_data['purchase_time'].dt.dayofweek\n",
    "fraud_data['time_since_signup'] = (fraud_data['purchase_time'] - fraud_data['signup_time']).dt.total_seconds() / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e1f23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transaction Frequency and Velocity\n",
    "fraud_data['transaction_count'] = fraud_data.groupby('user_id')['purchase_time'].transform('count')\n",
    "fraud_data['velocity'] = fraud_data['purchase_value'] / (fraud_data['time_since_signup'] + 1)  # Avoid division by zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: Class Distribution\n",
    "print(\"Fraud_Data Class Distribution:\")\n",
    "print(fraud_data['class'].value_counts(normalize=True))\n",
    "print(\"\\nCreditcard Class Distribution:\")\n",
    "print(creditcard['Class'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90651750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle Class Imbalance with SMOTE (applied later during model training)\n",
    "\n",
    "# Encode Categorical Features and Scale Numerical Features\n",
    "categorical_features = ['source', 'browser', 'sex', 'country']\n",
    "numerical_features = ['purchase_value', 'age', 'hour_of_day', 'day_of_week', 'time_since_signup', 'transaction_count', 'velocity']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Model Building and Training\n",
    "\n",
    "# Prepare Fraud_Data\n",
    "X_fraud = fraud_data.drop(['class', 'user_id', 'signup_time', 'purchase_time', 'device_id', 'ip_address'], axis=1)\n",
    "y_fraud = fraud_data['class']\n",
    "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(X_fraud, y_fraud, test_size=0.2, random_state=42, stratify=y_fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Creditcard Data\n",
    "X_credit = creditcard.drop('Class', axis=1)\n",
    "y_credit = creditcard['Class']\n",
    "X_train_credit, X_test_credit, y_train_credit, y_test_credit = train_test_split(X_credit, y_credit, test_size=0.2, random_state=42, stratify=y_credit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be53b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_fraud_smote, y_train_fraud_smote = smote.fit_resample(preprocessor.fit_transform(X_train_fraud), y_train_fraud)\n",
    "X_train_credit_smote, y_train_credit_smote = smote.fit_resample(X_train_credit, y_train_credit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13013d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Models\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e1a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Models for Fraud_Data\n",
    "pipeline_logreg_fraud = Pipeline([('preprocessor', preprocessor), ('classifier', logreg)])\n",
    "pipeline_rf_fraud = Pipeline([('preprocessor', preprocessor), ('classifier', rf)])\n",
    "\n",
    "pipeline_logreg_fraud.fit(X_train_fraud, y_train_fraud)\n",
    "pipeline_rf_fraud.fit(X_train_fraud, y_train_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c1029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Models\n",
    "def evaluate_model(model, X_test, y_test, dataset_name):\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "    auc_pr = auc(recall, precision)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n{dataset_name} Evaluation:\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    return auc_pr, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0bc73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud_Data Evaluation\n",
    "auc_pr_logreg_fraud, f1_logreg_fraud = evaluate_model(pipeline_logreg_fraud, X_test_fraud, y_test_fraud, \"Fraud_Data Logistic Regression\")\n",
    "auc_pr_rf_fraud, f1_rf_fraud = evaluate_model(pipeline_rf_fraud, X_test_fraud, y_test_fraud, \"Fraud_Data Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4282b349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Models for Creditcard Data\n",
    "logreg.fit(X_train_credit_smote, y_train_credit_smote)\n",
    "rf.fit(X_train_credit_smote, y_train_credit_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6359020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creditcard Evaluation\n",
    "auc_pr_logreg_credit, f1_logreg_credit = evaluate_model(logreg, X_test_credit, y_test_credit, \"Creditcard Logistic Regression\")\n",
    "auc_pr_rf_credit, f1_rf_credit = evaluate_model(rf, X_test_credit, y_test_credit, \"Creditcard Random Forest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dea117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Selection Justification\n",
    "best_model = 'Random Forest' if (auc_pr_rf_fraud + auc_pr_rf_credit) > (auc_pr_logreg_fraud + auc_pr_logreg_credit) else 'Logistic Regression'\n",
    "print(f\"\\nBest Model: {best_model}\")\n",
    "print(\"Justification: Random Forest typically performs better on imbalanced datasets due to its ability to capture complex patterns and interactions between features, which is critical for fraud detection.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec8a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Model Explainability with SHAP\n",
    "# Use Random Forest for explainability (assuming it performs better)\n",
    "X_test_fraud_transformed = preprocessor.transform(X_test_fraud)\n",
    "explainer = shap.TreeExplainer(pipeline_rf_fraud.named_steps['classifier'])\n",
    "shap_values = explainer.shap_values(X_test_fraud_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88862211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate SHAP Summary Plot\n",
    "feature_names = numerical_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    "shap.summary_plot(shap_values[1], X_test_fraud_transformed, feature_names=feature_names)\n",
    "plt.savefig('shap_summary_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2fbcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation\n",
    "print(\"\\nSHAP Summary Plot Interpretation:\")\n",
    "print(\"The SHAP summary plot shows the impact of each feature on the model's prediction of fraud. Features like 'time_since_signup' and 'velocity' are likely key drivers, indicating that rapid transactions after signup are strong indicators of fraud. Categorical features like 'country' and 'source' also contribute, suggesting geographic and acquisition channel patterns in fraudulent behavior.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
